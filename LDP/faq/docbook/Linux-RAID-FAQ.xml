<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN" "http://www.oasis-open.org/docbook/xml/4.2/docbookx.dtd">

<article class="faq" id="index">

 <articleinfo>
  <title>Linux-RAID FAQ</title>

  <author>
     <firstname>Gregory</firstname>
     <surname>Leblanc</surname>
     <email>gleblanc@linuxweasel.com</email>
  </author>

  <revhistory>

   <revision>
    <revnumber>v0.0.12</revnumber>
    <date>2003-03-05</date>
    <authorinitials>gml</authorinitials>
    <revremark>Fleshed out questions that cover using mdadm, small formatting
    changes</revremark>
   </revision>

   <revision>
    <revnumber>v0.0.11</revnumber>
    <date>2003-01-08</date>
    <authorinitials>gml</authorinitials>
    <revremark>Updated Archive Locations, information on when to patch, added
    a note about old patches being missing, removed question about the
    raidtools being dangerous (since they don't appear to be so labeled any
    longer).  </revremark>
   </revision>

   <revision>
    <revnumber>v0.0.10</revnumber>
    <date>24 April 2001</date>
    <authorinitials>gml</authorinitials>
    <revremark>
     Added a new section and question about benchmarking.</revremark>
   </revision>

  </revhistory>


  <abstract>
    <para>This is a FAQ for the Linux-RAID mailing list, hosted on
    vger.kernel.org.  vger.rutgers.edu is gone, so don't bother
    looking for it.  It's intended as a supplement to the existing
    Linux-RAID HOWTO, to cover questions that keep occurring on the
    mailing list.  PLEASE read this document before your post to the
    list.</para>

  </abstract>

  <legalnotice>

   <title>Linux RAID FAQ Copyright</title>

   <para>This documentation was developed for the Linux Documentation Project
   by Gregory Leblanc.</para>

   <para>Redistribution and use in source (XML DocBook) and 'compiled' forms
   (XML, HTML, PDF, PostScript, RTF and so forth) with or without
   modification, are permitted provided that the following conditions are
   met:</para>

    <orderedlist>
      <listitem>
        <para>Redistributions of source code (XML DocBook) must
          retain the above copyright notice, this list of conditions
          and the following disclaimer as the first lines of this file
          unmodified.</para>
      </listitem>

      <listitem>
        <para>Redistributions in compiled form (transformed to other
          DTDs, converted to PDF, PostScript, RTF and other formats)
          must reproduce the above copyright notice, this list of
          conditions and the following disclaimer in the documentation
          and/or other materials provided with the
          distribution.</para>
      </listitem>
    </orderedlist>

    <important>
      <para>THIS DOCUMENTATION IS PROVIDED BY THE GREGORY LEBLANC "AS IS" AND
      ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
      IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
      PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETWORKS ASSOCIATES
      TECHNOLOGY, INC BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
      EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
      PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
      PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
      LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
      NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
      DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</para>
    </important>
  </legalnotice>

 </articleinfo>

 <qandaset>

  <qandadiv id="general">
   <title>General</title>

   <qandaentry id="archives">
    <question>
     <para>Where can I find archives for the linux-raid mailing
     list?</para>
    </question>

    <answer>
     <para>The only archives left seem to be available at <ulink
     url="http://marc.theaimsgroup.com/?l=linux-raid&amp;r=1&amp;w=2">http://marc.theaimsgroup.com/?l=linux-raid&amp;r=1&amp;w=2</ulink></para>
    </answer>
   </qandaentry>

   <qandaentry id="wherefaq">
    <question>
     <para>Where can I find the latest version of this FAQ?</para>
    </question>

    <answer>
     <para>The latest version of this FAQ will be available from the
     LDP website at <ulink
     url="http://www.tldp.org/FAQ/">http://www.tldp.org/FAQ/</ulink>.</para>
    </answer>
   </qandaentry>


   <qandaentry id="listcovers">
    <question>
     <para>What sorts of things does this list cover?</para>
    </question>

    <answer>
     <para>Well, obviously this list covers RAID in relation to
     Linux.  Most of the discussions are related to the raid code
     that's been built into the Linux kernel.  There are also a few
     discussions on getting hardware based RAID controllers working
     using Linux as the operating system.  Any and all of these
     discussions are valid for this list.</para>
    </answer>
   </qandaentry>

  </qandadiv>


  <qandadiv id="kernel">
   <title>Kernel</title>

   <qandaentry id="whoneedstopatch">
    <question>
     <para>I'm running <replaceable>[insert your linux distribution
     here]</replaceable>.  Do I need to patch my kernel to make RAID
     work?</para>
     </question>

    <answer>
     <para>At this point, most major distributions are shipping with a 2.4
     based kernel, which already includes the necessary patches.  If your
     distribution is still using a 2.2.x kernel, upgrade!</para>
     <para>
      If you download a 2.2.x kernel from ftp.kernel.org, then you
      will need to patch your kernel.</para>
    </answer>
   </qandaentry>

   <qandaentry id="needtopatch">
    <question>
     <para>How can I tell if I need to patch my kernel?</para>
    </question>

    <answer>
     <para>That depends on which kernel series you're using.  If
     you're using the 2.4.x kernels, then you've already got the
     latest RAID code that's available.  If you're running 2.2.x, see
     the following instructions on how to find out.</para>

     <para>The easiest way is to check what's in
     <filename>/proc/mdstat</filename>.  Here's a sample from a 2.2.x
     kernel, <emphasis>with</emphasis> the RAID patches applied.

      <screen format="linespecific"> 

[gleblanc@grego1 gleblanc]$ cat /proc/mdstat
Personalities : [linear] [raid0] [raid1] [raid5] [translucent]
read_ahead not set
unused devices: &lt;none&gt;
      </screen>

If the contents of <filename>/proc/mdstat</filename> looks like the
     above, then you don't need to patch your kernel.</para> <para>The
     "Personalities" line in your kernel may not look exactly like the
     above, if you have RAID compiled as modules.  Most distributions
     will have RAID compiled as modules to save space on the boot
     diskette.  If you're not using any RAID sets, then you will
     probably see a blank space at the end of the "Personalities"
     line, don't worry, that just means that the RAID modules aren't
     loaded yet.</para>

     <para>Here's a sample from a 2.2.x kernel,
     <emphasis>without</emphasis> the RAID patches applied.

      <screen format="linespecific">

[root@serek ~]# cat /proc/mdstat 
Personalities : [1 linear] [2 raid0] 
read_ahead not set 
md0 : inactive 
md1 : inactive 
md2 : inactive 
md3 : inactive 

      </screen>

<emphasis>If your <filename>/proc/mdstat</filename> looks like this
one, then you need to patch your kernel.</emphasis></para>
    </answer>
   </qandaentry>

   <qandaentry id="wherepatches">
    <question>
     <para>Where can I get the latest RAID patches for my kernel?</para>
    </question>

    <answer>
     <para>The patches for the 2.2.x kernels up to, and including,
      2.2.13 are available from <ulink
      url="ftp://ftp.kernel.org/pub/linux/daemons/raid/alpha/">ftp.kernel.org</ulink>.
      Use the kernel patch that most closely matches your kernel
      revision.  For example, the 2.2.11 patch can also be used on
      2.2.12 and 2.2.13.  <important>
       <para>These patches are no longer available
       from this location!  I haven't been able to find the new location for
       them, please email me if you know where they've gone.</para>
      </important>
</para> 

     <para>The patches for 2.2.14 and later kernels are at <ulink
      url="http://people.redhat.com/mingo/raid-patches/">http://people.redhat.com/mingo/raid-patches/</ulink>.
      Use the right patch for your kernel, these patches haven't
      worked on other kernel revisions.  Please use something like
      wget/curl/lftp to retrieve this patch, as it's easier on the
      server than using a client like Netscape.  Downloading patches
      with Lynx has been unsuccessful for me; wget may be the easiest
      way.</para>
     </answer>
   </qandaentry>

   <qandaentry id="howtopatch">
     <question>
      <para>How do I apply the patch to a kernel that I just
      downloaded from ftp.kernel.org?</para>
     </question>

    <answer>
     <para>First, unpack the kernel into some directory, generally
     people use <filename class="directory">/usr/src/linux</filename>.
     Change to this directory, and type <command>patch -p1 &lt;
     /path/to/raid-version.patch</command>.

      <informalexample>
       <para>On my RedHat 6.2 system, I decompressed the 2.2.16 kernel
       into <filename
       class="directory">/usr/src/linux-2.2.16</filename>.  From
       <filename class="directory">/usr/src/linux-2.2.16</filename>, I
       type in <command>patch -p1 &lt;
       <replaceable>/home/gleblanc/raid-2.2.16-A0</replaceable></command>.
       Then I rebuild the kernel using <command>make
       menuconfig</command> and related builds.</para>
      </informalexample>

    </para>
    </answer>
   </qandaentry>

   <qandaentry id="whichdrives">
    <question>
     <para>What kind of drives can I use RAID with?  Do only SCSI or
     IDE drives work?  Do I need different patches for different kinds
     of drives?</para>
    </question>

    <answer>
     <para>Software RAID works with any block device in the Linux
     kernel.  This includes IDE and SCSI drives, as well as most
     harware RAID controllers.  There are no different patches for IDE
     drives vs. SCSI drives.</para>
    </answer>
   </qandaentry>

  </qandadiv>

  <qandadiv id="tools">
   <title>RAID tools</title>

   <qandaentry id="whattools">

    <question>
     <para>What tools are available for dealing with my Linux Software RAID
     arrays?</para>
    </question>

    <answer>
     <para>There are currently two sets of tools available.  Both sets work
    quite well, and have essentially the same functionalty.  I recommend the
    newer set of tools, because they're much easier to use, but I'll mention
    where to get the older tools as well.</para>

     <para>The new set of tools is called <application>mdadm</application>.
     It doesn't have much of a homepage, but you can download tarballs and
      RPMs from <ulink
     url="http://www.cse.unsw.edu.au/~neilb/source/mdadm/">http://www.cse.unsw.edu.au/~neilb/source/mdadm/</ulink>.
      I suggest that anyone who isn't already familar with the 'raidtools'
     package use these (and in fact, I suggest that folks who already know the
     raidtools package switch over to these).</para>

     <para>The older set of tools is called
      <application>raidtools</application>.  They're available from <ulink
      url="http://people.redhat.com/mingo/raidtools/">http://people.redhat.com/mingo/raidtools/</ulink>.
      I believe there are other locations available, since Red Hat Linux is
      shipping based on a tarball numbered 1.00.3, which I can't find online.
      If anybody knows where these are, please let me know.</para>
    </answer>
   </qandaentry>

  </qandadiv>

  <qandadiv id="failrecover">
   <title>Disk Failures and Recovery</title>

   <qandaentry id="hasfailed">
    <question>
     <para>How can I tell if one of the disks in my RAID array has
     failed?</para>
    </question>

    <answer>
     <para>A couple of things should indicate when a disk has failed.
     There should be quite a few messages in
     <filename>/var/log/messages</filename> indicating errors
     accessing that device, which should be a good indication that
     something is wrong.</para> <para>You should also notice that your
     <filename>/proc/mdstat</filename> looks different.  Here's a snip
     from a good /proc/mdstat

      <screen format="linespecific"> 

[gleblanc@grego1 gleblanc]$ cat /proc/mdstat
Personalities : [linear] [raid0] [raid1] [raid5] [translucent]
read_ahead not set
md0 : active raid1 sdb5[0] sda5[1] 32000 blocks [2/2] [UU]
unused devices: &lt;none&gt;
      </screen>
     </para>

     <para>And here's one from a <filename>/proc/mdstat</filename>
     where one of the RAID sets has a missing disk.

      <screen format="linespecific"> 

[gleblanc@grego1 gleblanc]$ cat /proc/mdstat
Personalities : [linear] [raid0] [raid1] [raid5] [translucent]
read_ahead not set
md0 : active raid1 sdb5[0] sda5[1] 32000 blocks [2/1] [U_]
unused devices: &lt;none&gt;
      </screen>
     </para>

     <para>I don't know if <filename>/proc/mdstat</filename> will
     reflect the status of a HOT SPARE.  If you have set one up, you
     should be watching <filename>/var/log/messages</filename> for any
     disk failures.  I'd like to get some logs of a disk failure, and
     <filename>/proc/mdstat</filename> from a system with a hot
     spare.</para>
    </answer>

   </qandaentry>

   <qandaentry id="missingdisk">
    <question>
     <para>So my RAID set is missing a disk, what do I do now?</para>
    </question>

    <answer>
     <para>Software-RAID generally doesn't mark a disk as bad unless it is, so
     you probably need a new disk.  Most decent quality disks have a 3 year
     warranty, but some exceptional (and expensive) SCSI hard drives may have
     wararnties as long as 5 years, or even longer.  More and more hard drive
     vendors are giving a 1 year warranty on their "consumer" drives.  I
     suggest avoiding any drive with a 1 year warranty if at all possible.
     Try to have the manufacturer replace the failed disk if it's still under
     warranty.</para>

     <para>When you get the new disk, power down the system, and install it,
     then partition the drive so that it has partitions the size of your
     missing RAID partitions.  Once you have the partitions set up properly,
     just run <command>mdadm --add <replaceable>/dev/md0</replaceable>
     <replaceable>/dev/hdc1</replaceable></command>, where
     <replaceable>/dev/md0</replaceable> is the RAID array you're adding the
     partition to, and <replaceable>/dev/hdc1</replaceable> is the partition
     that you're trying to add.  Reconstruction should start
     immediately.</para>

     <para>If you would prefer to use the RAIDtools suite, you can use the
     command <command>raidhotadd</command> to put the new disk into the array
     and begin reconstruction.  See <ulink
     url="http://www.LinuxDoc.org/HOWTO/Software-RAID-HOWTO-6.html">Chapter
     6</ulink> of the <ulink
     url="http://www.LinuxDoc.org/HOWTO/Software-RAID-HOWTO.html">Software
     RAID HOWTO</ulink> for more information.</para>

    </answer>
   </qandaentry>


   <qandaentry id="overlap">
    <question>
     <para><command>dmesg</command> shows <quote>md: serializing resync,
       <replaceable>md4</replaceable> has overlapping physical units
       with <replaceable>md5</replaceable></quote> (where md4 and md5 are two
       of your software RAID devices). What does this mean?</para>
    </question>

    <answer>
     <para>In that message <quote>physical units</quote> refers to
     disks, and not to blocks on the disks.  Since there is more than
     one RAID array that needs resyncing on one of the disks in use for your
     RAID arrays, the RAID code is going to sync md4 first, and md5 second, to
     avoid excessive seeks (also called thrashing), which would drastically
     slow the resync process.</para>
    </answer>
   </qandaentry>

  </qandadiv>


  <qandadiv id="benchmarking">
   <title>Benchmarking</title>


   <qandaentry id="howbenchmark">
    <question>
     <para>How should I benchmark my RAID devices?  Are there any
     tools that work particularly well?</para>
    </question>

    <answer>
     <para>There are really a few options for benchmarking your RAID
     array, depending on what you're looking to test.  RAID offers the
     greatest speed increases when there are multiple threads reading
     from the same RAID volume.</para>

     <para>One tool specificly designed to test and show off these
     performance gains is <ulink
     url="http://tiobench.sourceforge.net/"
     type="http"><application>tiobench</application></ulink>.  It uses
     multiple read and write threads on the disk, and has some pretty
     good reporting.</para>

     <para>Another good tool to use is <ulink
     url="http://www.coker.com.au/bonnie++/"
     type="http"><application>bonnie++</application></ulink>.  It
     seems to be more targeted at benchmarking single drives that at
     RAID, but still provides useful information.</para>

     <para>One tool <emphasis>NOT</emphasis> to use is
     <application>hdparm</application>.  It does not give useful
     performance numbers for any drives that I've heard about, and has
     been known to give some incredibly off-the-wall numbers as well.
      If you want to do <emphasis>real</emphasis> benchmarking, use
     one of the tools listed above.</para>
    </answer>
   </qandaentry>

  </qandadiv>

 </qandaset>

</article>


<!-- Keep this comment at the end of the file
Local variables:
mode: xml
sgml-omittag:t
sgml-shorttag:t
sgml-namecase-general:t
sgml-general-insert-case:lower
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:1
sgml-indent-data:1
sgml-parent-document:nil
sgml-exposed-tags:nil
sgml-local-catalogs:nil
sgml-local-ecat-files:nil
End:
-->
